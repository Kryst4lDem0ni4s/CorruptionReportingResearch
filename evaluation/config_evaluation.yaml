# ============================================
# Corruption Reporting System - Evaluation Configuration
# Version: 1.0.0
# Description: Configuration for research evaluation suite
# ============================================

# ============================================
# GENERAL SETTINGS
# ============================================

general:
  version: "1.0.0"
  experiment_name: "corruption_reporting_evaluation"
  random_seed: 42
  verbose: true
  log_level: "INFO"
  
  # Output settings
  output_dir: "evaluation/results"
  figures_dir: "evaluation/results/figures"
  save_intermediate: true
  overwrite_existing: false

# ============================================
# DATASET CONFIGURATION
# ============================================

datasets:
  # FaceForensics++ Dataset
  faceforensics:
    enabled: false
    dataset_type: "deepfake_detection"
    
    # Download settings
    download:
      enabled: true
      url: "https://github.com/ondyari/FaceForensics/releases"
      extraction_method: "c23"  # Compression level
      quality: "raw"  # raw, c23, c40
    
    # Sampling settings
    sampling:
      sample_size: 500  # Number of images to use
      stratified: true  # Stratified sampling
      real_fake_ratio: 0.5  # 50% real, 50% fake
      split: "test"  # train, val, test
    
    # Preprocessing
    preprocessing:
      resize: [224, 224]  # CLIP input size
      normalize: true
      augmentation: false  # No augmentation for evaluation
    
    # Target metrics
    target_metrics:
      auroc: 0.90  # Paper target
      auroc_threshold: 0.75  # Minimum acceptable
      precision: 0.85
      recall: 0.85
      f1_score: 0.85
  
  # Celeb-DF v2 Dataset
  celebdf:
    enabled: true
    dataset_type: "deepfake_detection"

    # Download settings
    download:
      enabled: true
      url: "https://github.com/yuezunli/CELEB-DF-v2"  # Requires manual request, but we'll try
      extraction_method: "zip"

    # Sampling settings
    sampling:
      sample_size: 200  # Number of videos/images to use
      stratified: true  # Stratified sampling
      real_fake_ratio: 0.5  # 50% real, 50% fake
      split: "test"  # train, val, test

    # Preprocessing
    preprocessing:
      resize: [224, 224]
      extract_frames: true  # Extract frames from videos
      frames_per_video: 5

  # Real and Fake Face Detection
  real-and-fake-face-detection:
    enabled: true
    dataset_type: "deepfake_detection"

    # Download settings
    download:
      enabled: true
      url: "https://www.kaggle.com/datasets/ciplab/real-and-fake-face-detection"
      extraction_method: "zip"
    
    # Sampling settings
    sampling:
      sample_size: 200
      stratified: true
      real_fake_ratio: 0.5
      split: "test"

    # Preprocessing
    preprocessing:
      resize: [224, 224]

  # Synthetic Coordinated Attacks
  synthetic_attacks:
    enabled: true
    dataset_type: "coordination_detection"
    
    # Generation settings
    generation:
    attack_patterns:
      - name: "linguistic_similarity"
        enabled: true
        similarity_threshold: 0.80
      - name: "temporal_clustering"
        enabled: true
        time_window_hours: 2
      - name: "content_similarity"
        enabled: true
        similarity_threshold: 0.75
    
    # Target metrics
    target_metrics:
      precision: 0.70
      recall: 0.70
      f1_score: 0.70
  
  # Counter-Evidence Dataset
  counter_evidence:
    enabled: true
    dataset_type: "bayesian_aggregation"
    
    # Generation settings
    generation:
      num_cases: 50  # Number of accusation-defense pairs
      defense_types:
        - "verified_identity"  # With identity verification
        - "unverified_identity"  # Without identity verification
        - "partial_refutation"  # Partial counter-evidence
        - "full_refutation"  # Complete counter-evidence
    
    # Bayesian parameters
    bayesian_params:
      presumption_weight: 1.3  # Presumption of innocence
      identity_bonus: 1.2  # Verified identity bonus
      prior_guilty: 0.3  # Prior probability of guilt
    
    # Target metrics
    target_metrics:
      false_positive_reduction: 0.20  # 20% reduction target
      precision_improvement: 0.15

# ============================================
# MODEL CONFIGURATION
# ============================================

models:
  # CLIP Model (Deepfake Detection)
  clip:
    model_name: "openai/clip-vit-base-patch32"
    device: "cpu"  # cpu, cuda, mps
    batch_size: 16
    num_workers: 4
    
    # Test-time augmentation
    tta:
      enabled: true
      num_augmentations: 10
      transforms:
        - "horizontal_flip"
        - "rotation"
        - "brightness"
        - "contrast"
  
  # Sentence Transformer (Text Analysis)
  sentence_transformer:
    model_name: "sentence-transformers/all-MiniLM-L6-v2"
    device: "cpu"
    batch_size: 32
  
  # Wav2Vec2 (Audio Analysis)
  wav2vec2:
    model_name: "facebook/wav2vec2-base"
    device: "cpu"
    batch_size: 8
    enabled: false  # Optional for audio evidence

# ============================================
# METRICS CONFIGURATION
# ============================================

metrics:
  # Deepfake Detection Metrics
  deepfake_detection:
    metrics_to_compute:
      - "auroc"
      - "precision"
      - "recall"
      - "f1_score"
      - "accuracy"
      - "confusion_matrix"
      - "roc_curve"
      - "precision_recall_curve"
    
    # Classification thresholds
    thresholds:
      default: 0.5
      optimized: "auto"  # Find optimal threshold
      range: [0.1, 0.9]
      step: 0.05
    
    # Confidence intervals
    confidence_intervals:
      enabled: true
      method: "bootstrap"
      n_bootstraps: 1000
      confidence_level: 0.95
  
  # Coordination Detection Metrics
  coordination_detection:
    metrics_to_compute:
      - "precision"
      - "recall"
      - "f1_score"
      - "accuracy"
      - "confusion_matrix"
    
    # Graph-based metrics
    graph_metrics:
      - "modularity"
      - "clustering_coefficient"
      - "average_path_length"
    
    # Detection parameters
    detection_params:
      similarity_threshold: 0.70
      min_cluster_size: 3
      community_detection: "louvain"
  
  # Consensus Metrics
  consensus:
    metrics_to_compute:
      - "convergence_time"
      - "agreement_rate"
      - "fault_tolerance"
      - "decision_stability"
    
    # Consensus parameters
    consensus_params:
      num_validators: 15
      devil_advocate_ratio: 0.10
      fault_tolerance: 0.33
      max_iterations: 10
      convergence_threshold: 0.80
  
  # Bayesian Aggregation Metrics
  bayesian_aggregation:
    metrics_to_compute:
      - "false_positive_rate"
      - "false_negative_rate"
      - "precision"
      - "recall"
      - "decision_change_rate"
    
    # Before/after comparison
    comparison:
      enabled: true
      metrics:
        - "accuracy_improvement"
        - "precision_improvement"
        - "false_positive_reduction"

# ============================================
# VISUALIZATION CONFIGURATION
# ============================================

visualization:
  # General settings
  general:
    dpi: 300
    format: "png"
    style: "seaborn-v0_8-darkgrid"
    context: "paper"
    font_scale: 1.2
    color_palette: "Set2"
  
  # Figure dimensions
  figure_sizes:
    single_plot: [8, 6]
    double_plot: [12, 6]
    grid_plot: [10, 10]
  
  # Plots to generate
  plots:
    # ROC Curve
    roc_curve:
      enabled: true
      title: "ROC Curve - Deepfake Detection"
      xlabel: "False Positive Rate"
      ylabel: "True Positive Rate"
      show_diagonal: true
      show_threshold: true
    
    # Precision-Recall Curve
    precision_recall_curve:
      enabled: true
      title: "Precision-Recall Curve"
      xlabel: "Recall"
      ylabel: "Precision"
      show_baseline: true
    
    # Confusion Matrix
    confusion_matrix:
      enabled: true
      title: "Confusion Matrix"
      normalize: true
      cmap: "Blues"
      annotations: true
    
    # Score Distribution
    score_distribution:
      enabled: true
      title: "Credibility Score Distribution"
      bins: 50
      kde: true
      separate_classes: true
    
    # Network Graph
    network_graph:
      enabled: true
      title: "Coordination Detection Network"
      layout: "spring"
      node_size: 500
      edge_width_scale: 2.0
      show_labels: true
    
    # Convergence Plot
    convergence_plot:
      enabled: true
      title: "Consensus Convergence"
      xlabel: "Iteration"
      ylabel: "Agreement Rate"
      show_threshold: true

# ============================================
# BENCHMARK CONFIGURATION
# ============================================

benchmarks:
  # Latency Testing
  latency:
    enabled: true
    num_samples: 100
    warmup_samples: 10
    
    # Components to benchmark
    components:
      - "submission_processing"
      - "credibility_assessment"
      - "coordination_detection"
      - "consensus_simulation"
      - "report_generation"
    
    # Target latencies (milliseconds)
    targets:
      submission_processing: 5000  # 5 seconds
      credibility_assessment: 3000  # 3 seconds
      coordination_detection: 2000  # 2 seconds
      consensus_simulation: 1000  # 1 second
      report_generation: 4000  # 4 seconds
  
  # Throughput Testing
  throughput:
    enabled: true
    duration_seconds: 60
    concurrent_requests: [1, 5, 10]
    
    # Target throughput (submissions/hour)
    target_throughput: 20
  
  # Memory Profiling
  memory:
    enabled: true
    profile_interval: 0.1  # seconds
    
    # Memory limits
    limits:
      max_memory_mb: 8192  # 8GB
      max_model_memory_mb: 2048  # 2GB per model

# ============================================
# EXPERIMENTAL SETTINGS
# ============================================

experiments:
  # Deepfake Detection
  deepfake_detection:
    enabled: true
  
  # Coordination Detection
  coordination_detection:
    enabled: true
    
  # Consensus Simulation
  consensus_simulation:
    enabled: true
    
  # Counter Evidence
  counter_evidence:
    enabled: true
    
  # End-to-End
  end_to_end:
    enabled: true

  # Ablation Studies
  ablation:
    enabled: false
    
    # Components to ablate
    components:
      - "test_time_augmentation"
      - "ensemble_methods"
      - "coordination_detection"
      - "counter_evidence"
  
  # Hyperparameter Tuning
  hyperparameter_tuning:
    enabled: false
    
    # Parameters to tune
    parameters:
      credibility_threshold: [0.5, 0.6, 0.7, 0.8]
      similarity_threshold: [0.6, 0.7, 0.8, 0.9]
      num_validators: [10, 15, 20, 25]
  
  # Comparative Analysis
  comparative:
    enabled: true
    
    # Comparisons to make
    comparisons:
      - name: "pretrained_vs_baseline"
        baseline: "random_classifier"
      - name: "with_vs_without_tta"
        baseline: "no_augmentation"
      - name: "with_vs_without_counter_evidence"
        baseline: "no_defense"

# ============================================
# REPORTING CONFIGURATION
# ============================================

reporting:
  # Report format
  format: "markdown"  # markdown, latex, html
  
  # Sections to include
  sections:
    - "executive_summary"
    - "methodology"
    - "results"
    - "visualizations"
    - "performance_analysis"
    - "limitations"
    - "conclusions"
  
  # Metadata
  metadata:
    title: "Corruption Reporting System - Evaluation Report"
    authors:
      - "Research Team"
    date: "auto"
    version: "1.0.0"
  
  # Export formats
  export:
    markdown: true
    pdf: false  # Requires pandoc
    html: false
    json: true

# ============================================
# REPRODUCIBILITY
# ============================================

reproducibility:
  # Random seeds
  random_seed: 42
  numpy_seed: 42
  torch_seed: 42
  
  # Deterministic mode
  deterministic: true
  
  # Save settings
  save_config: true
  save_environment: true
  save_code_snapshot: false
  
  # Git tracking
  git:
    track_commit: true
    track_diff: true
    require_clean: false

# ============================================
# RESOURCE MANAGEMENT
# ============================================

resources:
  # CPU settings
  cpu:
    num_workers: 4
    max_threads: 8
  
  # Memory settings
  memory:
    max_usage_gb: 8
    cache_size_gb: 2
    clear_cache_interval: 100  # batches
  
  # Disk settings
  disk:
    max_cache_size_gb: 10
    cleanup_on_exit: false
  
  # GPU settings (if available)
  gpu:
    enabled: false
    device_id: 0
    memory_fraction: 0.9
